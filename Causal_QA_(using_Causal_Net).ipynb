{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Causal QA (using Causal Net).ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hkayesh/causal-qa/blob/master/Causal_QA_(using_Causal_Net).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvyQ_9a77MC7",
        "colab_type": "text"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH5NEdrr659o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "from gensim.utils import tokenize, lemmatize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from google.colab import drive \n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_fy5T80qu7_",
        "colab_type": "code",
        "outputId": "58a739d5-3890-4274-9c1c-1c15f531ef78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "# installing pattern package erquired for gensim's lemmatize() \n",
        "!pip install git+git://github.com/pattern3/pattern.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/pattern3/pattern.git\n",
            "  Cloning git://github.com/pattern3/pattern.git to /tmp/pip-req-build-__vm84do\n",
            "  Running command git clone -q git://github.com/pattern3/pattern.git /tmp/pip-req-build-__vm84do\n",
            "Requirement already satisfied (use --upgrade to upgrade): pattern==2.6 from git+git://github.com/pattern3/pattern.git in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from pattern==2.6) (4.6.3)\n",
            "Requirement already satisfied: cherrypy in /usr/local/lib/python3.6/dist-packages (from pattern==2.6) (18.5.0)\n",
            "Requirement already satisfied: docx in /usr/local/lib/python3.6/dist-packages (from pattern==2.6) (0.2.4)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.6/dist-packages (from pattern==2.6) (5.2.1)\n",
            "Requirement already satisfied: pdfminer3k in /usr/local/lib/python3.6/dist-packages (from pattern==2.6) (1.3.1)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.6/dist-packages (from pattern==2.6) (3.17.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.6/dist-packages (from cherrypy->pattern==2.6) (8.0.2)\n",
            "Requirement already satisfied: portend>=2.1.1 in /usr/local/lib/python3.6/dist-packages (from cherrypy->pattern==2.6) (2.6)\n",
            "Requirement already satisfied: jaraco.collections in /usr/local/lib/python3.6/dist-packages (from cherrypy->pattern==2.6) (3.0.0)\n",
            "Requirement already satisfied: cheroot>=8.2.1 in /usr/local/lib/python3.6/dist-packages (from cherrypy->pattern==2.6) (8.2.1)\n",
            "Requirement already satisfied: zc.lockfile in /usr/local/lib/python3.6/dist-packages (from cherrypy->pattern==2.6) (2.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from docx->pattern==2.6) (4.2.6)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.6/dist-packages (from docx->pattern==2.6) (6.2.2)\n",
            "Requirement already satisfied: ply>=3.4 in /usr/local/lib/python3.6/dist-packages (from pdfminer3k->pattern==2.6) (3.11)\n",
            "Requirement already satisfied: pytest>=2.0 in /usr/local/lib/python3.6/dist-packages (from pdfminer3k->pattern==2.6) (3.6.4)\n",
            "Requirement already satisfied: tempora>=1.8 in /usr/local/lib/python3.6/dist-packages (from portend>=2.1.1->cherrypy->pattern==2.6) (2.1.0)\n",
            "Requirement already satisfied: jaraco.text in /usr/local/lib/python3.6/dist-packages (from jaraco.collections->cherrypy->pattern==2.6) (3.2.0)\n",
            "Requirement already satisfied: jaraco.classes in /usr/local/lib/python3.6/dist-packages (from jaraco.collections->cherrypy->pattern==2.6) (3.1.0)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from jaraco.collections->cherrypy->pattern==2.6) (1.12.0)\n",
            "Requirement already satisfied: jaraco.functools in /usr/local/lib/python3.6/dist-packages (from cheroot>=8.2.1->cherrypy->pattern==2.6) (3.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from zc.lockfile->cherrypy->pattern==2.6) (42.0.2)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=2.0->pdfminer3k->pattern==2.6) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=2.0->pdfminer3k->pattern==2.6) (1.8.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=2.0->pdfminer3k->pattern==2.6) (19.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=2.0->pdfminer3k->pattern==2.6) (1.3.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern==2.6) (2018.9)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern==2.6) (1.0.2)\n",
            "Building wheels for collected packages: pattern\n",
            "  Building wheel for pattern (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pattern: filename=pattern-2.6-py2.py3-none-any.whl size=18553736 sha256=b7452a231a6b74605b07490ced30b61bf189f083598806ada6ed943f36167832\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vfevb7ee/wheels/42/86/32/4c2c2365f5f4247ff44ae48bb2290f4fb024b2d2a48bf52a32\n",
            "Successfully built pattern\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKSKukdgDNIY",
        "colab_type": "code",
        "outputId": "895a22e8-353c-4179-a430-2fb5ecc8b1db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# nltk.download('punkt')\n",
        "# nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "# nltk.download('wordnet')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhxDyekj7Q6C",
        "colab_type": "text"
      },
      "source": [
        "### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSCkKvF87UuZ",
        "colab_type": "code",
        "outputId": "bd0c5bf6-cb10-4c2f-91ad-c44998ba8036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb2iE-DI7ivT",
        "colab_type": "text"
      },
      "source": [
        "### Declare Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKUYHoPO7iBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_DIR = 'gdrive/My Drive/Research Data/CausalQA/datasets/'\n",
        "CAUSAL_TUPLES_DIR = 'gdrive/My Drive/Research Data/CausalQA/causalTuples/'\n",
        "CAUSAL_NET_FILE = 'gdrive/My Drive/Research Data/CausalQA/causal_net/causal_net_100k.pickle'\n",
        "CAUSAL_PAIRS_1M_ARTICLES_FILE = '/content/gdrive/My Drive/Research Data/CausalQA/causal_pairs_1M_articles.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky9dZg-R8Nvb",
        "colab_type": "text"
      },
      "source": [
        "### Load background dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfFuBWFi7gIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bg_tuples = []\n",
        "\n",
        "# causal_tuples_files = ['nyt_mar30_combo.argsC', 'apw_mar30_combo.argsC', 'afp_mar30_combo.argsC', 'ltw_mar30_combo.argsC', 'simpleWiki_mar19b_combo.argsC', 'xin_mar30_combo.argsC']\n",
        "# for causal_tuples_file in causal_tuples_files:\n",
        "#   with open(CAUSAL_TUPLES_DIR + causal_tuples_file, 'r') as rows:\n",
        "#     for index, row in enumerate(rows):\n",
        "#       splits = row.split('-->', 2)\n",
        "#       cause_phrase = re.sub('_[A-Z]+', '', splits[0]).strip().lower()\n",
        "#       effect_phrase = re.sub('_[A-Z]+', '', splits[1]).strip().lower()\n",
        "\n",
        "#       bg_tuples.append((cause_phrase, effect_phrase))\n",
        "\n",
        "# len(bg_tuples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvQxMzJp6HKm",
        "colab_type": "code",
        "outputId": "4f23e41e-57b0-4932-ff6b-b083ceb56659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "causal_pairs_df = pd.read_csv(CAUSAL_PAIRS_1M_ARTICLES_FILE, nrows=100000, lineterminator='\\n', error_bad_lines=False)\n",
        "print(causal_pairs_df.shape)\n",
        "\n",
        "bg_tuples.extend(list(zip(causal_pairs_df['sequence_a'], causal_pairs_df['sequence_b'])))\n",
        " "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Aolxdvu8oRN",
        "colab_type": "text"
      },
      "source": [
        "### Prepare Causal Network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyBqjdHG8mUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Preprocessor():\n",
        "  def __init__(self, params=list()):\n",
        "    self.lemmatize = True if 'lemmatize' in params else False\n",
        "\n",
        "  def preprocess(self, document):\n",
        "    \"\"\"\n",
        "    Run the preprocessing operations on the input string and returns processed string\n",
        "\n",
        "    :param document: a string to be preprocessed. \n",
        "    :return string: processed string \n",
        "    \"\"\"\n",
        "    processed_doc = document\n",
        "    processed_doc = self.lemmatize_doc(processed_doc) if self.lemmatize else processed_doc\n",
        "\n",
        "    return processed_doc.strip()\n",
        "\n",
        "\n",
        "  def lemmatize_doc(self, document):\n",
        "    \"\"\"\n",
        "    Apply lemmatization on each word of a string\n",
        "\n",
        "    :param document: a string\n",
        "    :return string: the string with lemmatized words \n",
        "    \"\"\"\n",
        "\n",
        "    processed_tokens= []\n",
        "    lemma_tokens = list(lemmatize(document, stopwords=set(stopwords.words('english'))))\n",
        "    for lemma_token in lemma_tokens:\n",
        "        try:\n",
        "          token = lemma_token.decode('ascii').split('/')[0] # Discard POS tags\n",
        "          processed_tokens.append(token)\n",
        "        except UnicodeDecodeError:\n",
        "          continue\n",
        "\n",
        "    return ' '.join(processed_tokens)\n",
        "\n",
        "class CausalNetGenerator():\n",
        "  def __init__(self):\n",
        "     self.preprocessor = Preprocessor(['lemmatize'])\n",
        "  \n",
        "  def clean_up_text(self, causal_pairs):\n",
        "    clean_causal_pairs = []\n",
        "    for causal_pair in causal_pairs:\n",
        "      cause_clean_tokens = self.preprocessor.preprocess(causal_pair[0])\n",
        "      effect_clean_tokens = self.preprocessor.preprocess(causal_pair[1])\n",
        "\n",
        "      if len(cause_clean_tokens) > 0 and len(effect_clean_tokens) > 0:\n",
        "        clean_causal_pairs.append((cause_clean_tokens, effect_clean_tokens))\n",
        "\n",
        "    return clean_causal_pairs\n",
        "\n",
        "  def get_causal_token_pairs(self, causal_pair_phrase):\n",
        "      cause_tokens = list(tokenize(causal_pair_phrase[0]))\n",
        "      effect_tokens = list(tokenize(causal_pair_phrase[1]))\n",
        "      causal_pairs = []\n",
        "      for cause_token in cause_tokens:\n",
        "          cause_replicated_list = [cause_token] * len(effect_tokens)\n",
        "\n",
        "          causal_pairs += list(zip(cause_replicated_list, effect_tokens))\n",
        "\n",
        "      return causal_pairs\n",
        "\n",
        "  def create_or_update_directed_causal_graph(self, causal_pairs, graph=None):\n",
        "    if graph is None:\n",
        "      graph = nx.DiGraph()\n",
        "    \n",
        "    causal_pairs = self.clean_up_text(causal_pairs)\n",
        "\n",
        "    for causal_pair in causal_pairs:\n",
        "      causal_token_pairs = self.get_causal_token_pairs(causal_pair)\n",
        "      \n",
        "      for causal_token_pair in causal_token_pairs:\n",
        "        cause_token = causal_token_pair[0]\n",
        "        effect_token = causal_token_pair[1]\n",
        "\n",
        "        if cause_token not in graph:\n",
        "          graph.add_node(cause_token)\n",
        "        if effect_token not in graph:\n",
        "          graph.add_node(effect_token)\n",
        "\n",
        "        if graph.has_successor(cause_token, effect_token):\n",
        "          graph[cause_token][effect_token]['freq'] += 1\n",
        "        else:\n",
        "          graph.add_edge(cause_token, effect_token)\n",
        "          graph[cause_token][effect_token]['freq'] = 1\n",
        "\n",
        "    return graph\n",
        "\n",
        "causal_net_generator = CausalNetGenerator()\n",
        "causal_net = causal_net_generator.create_or_update_directed_causal_graph(bg_tuples)\n",
        "\n",
        "nx.write_gpickle(causal_net, CAUSAL_NET_FILE)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pee6qqhAqwp",
        "colab_type": "text"
      },
      "source": [
        "### Calcualte Strength Calcualtion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVwQBDvSAidJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class CausalStrengthCalculator:\n",
        "    def __init__(self, causal_net_file):\n",
        "        self.causal_net_file = causal_net_file\n",
        "        self.causal_net = nx.read_gpickle(self.causal_net_file)\n",
        "        self.N = len(self.causal_net.nodes())\n",
        "        self.M = sum([edge[2]['freq'] for edge in self.causal_net.edges(data=True)])\n",
        "\n",
        "    def get_prior_probas(self, i_c, j_e):\n",
        "        prior_probas = {\n",
        "            'p_of_i_c': 0,\n",
        "            'p_of_j_e': 0,\n",
        "            'p_of_i_c_and_j_e': 0\n",
        "        }\n",
        "\n",
        "        if self.causal_net.has_node(i_c) and self.causal_net.has_node(j_e) and self.causal_net.has_edge(i_c, j_e):\n",
        "            f_of_i_and_j_e = self.causal_net[i_c][j_e]['freq']\n",
        "            prior_probas['p_of_i_c_and_j_e'] = f_of_i_and_j_e/self.N\n",
        "\n",
        "        if self.causal_net.has_node(i_c):\n",
        "            number_of_pairs_with_i_c = sum([self.causal_net[i_c][successor]['freq'] for successor in self.causal_net.successors(i_c)])\n",
        "            prior_probas['p_of_i_c'] = number_of_pairs_with_i_c/self.M\n",
        "\n",
        "        if self.causal_net.has_node(j_e):\n",
        "            number_of_pairs_with_j_e = sum([self.causal_net[predecessor][j_e]['freq'] for predecessor in self.causal_net.predecessors(j_e)])\n",
        "            prior_probas['p_of_j_e'] = number_of_pairs_with_j_e/self.M\n",
        "\n",
        "        return prior_probas\n",
        "\n",
        "    def get_causal_strength(self, i_c, j_e, alpha=0.66, cs_lambda=0.5):\n",
        "        cs_of_i_c_and_j_e = 0\n",
        "        prior_probas = self.get_prior_probas(i_c, j_e)\n",
        "        if prior_probas['p_of_i_c'] > 0 and prior_probas['p_of_j_e'] > 0:\n",
        "            cs_nec_of_i_c_and_j_e = prior_probas['p_of_i_c_and_j_e'] / ((prior_probas['p_of_i_c'] ** alpha) * prior_probas['p_of_j_e'])\n",
        "            cs_suf_of_i_c_and_j_e = prior_probas['p_of_i_c_and_j_e'] / (prior_probas['p_of_i_c'] * (prior_probas['p_of_j_e'] ** alpha))\n",
        "            cs_of_i_c_and_j_e = (cs_nec_of_i_c_and_j_e ** cs_lambda) * (cs_suf_of_i_c_and_j_e ** (1 - cs_lambda))\n",
        "\n",
        "        return cs_of_i_c_and_j_e\n",
        "\n",
        "    def get_causality_score(self, candidate_causal_pair):\n",
        "        T_1 = list(tokenize(candidate_causal_pair[0]))\n",
        "        T_2 = list(tokenize(candidate_causal_pair[1]))\n",
        "\n",
        "        total_causal_strength = 0\n",
        "\n",
        "        for i_c in T_1:\n",
        "            for j_e in T_2:\n",
        "                causal_strength = self.get_causal_strength(i_c, j_e)\n",
        "                total_causal_strength += causal_strength\n",
        "\n",
        "        causal_score = total_causal_strength / (len(T_1) + len(T_2))\n",
        "\n",
        "        return causal_score\n",
        "\n",
        "# causal_strength_calculator = CausalStrengthCalculator(CAUSAL_NET_FILE)\n",
        "\n",
        "# causal_strength_calculator.get_causality_score(('blindness', 'disease'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tAvvamD4fuZ",
        "colab_type": "text"
      },
      "source": [
        "### Load Evaluation datasts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QXvik7w4eGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "semeval_file_path = DATASET_DIR + 'semeval-benchmark-v1.csv'\n",
        "risk_file_path = DATASET_DIR + 'risk-models-benchmark-v1.csv'\n",
        "nato_sfa_file_path = DATASET_DIR + 'nato-sfa-benchmark-v1.csv'\n",
        "ce_me_file_path = DATASET_DIR + 'ce-me-benchmark-v1.csv'\n",
        "ce_twitter_file_path = DATASET_DIR + 'twitter-causal-dataset.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zM0V-kO4m_O",
        "colab_type": "code",
        "outputId": "646b5701-1501-43c0-997c-b6392ef2e554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "sem_eval_df = pd.read_csv(semeval_file_path, names=['cause', 'effect', 'label'], header=None)\n",
        "sem_eval_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cause</th>\n",
              "      <th>effect</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dwarf</td>\n",
              "      <td>emission</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>disease</td>\n",
              "      <td>blindness</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>women</td>\n",
              "      <td>accident</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>reading</td>\n",
              "      <td>rage</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>snowstorm</td>\n",
              "      <td>losses</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       cause     effect   label\n",
              "0      dwarf   emission  causal\n",
              "1    disease  blindness  causal\n",
              "2      women   accident  causal\n",
              "3    reading       rage  causal\n",
              "4  snowstorm     losses  causal"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XotBV6XPeQ4",
        "colab_type": "code",
        "outputId": "213b0f39-d19f-4351-a11d-9d4e93976a6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "sem_eval_df[865:].sample(n=6, random_state=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cause</th>\n",
              "      <th>effect</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1465</th>\n",
              "      <td>protein</td>\n",
              "      <td>researchers</td>\n",
              "      <td>non_causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>921</th>\n",
              "      <td>rocks</td>\n",
              "      <td>pile</td>\n",
              "      <td>non_causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1349</th>\n",
              "      <td>copper</td>\n",
              "      <td>tissue</td>\n",
              "      <td>non_causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>949</th>\n",
              "      <td>article</td>\n",
              "      <td>criticisms</td>\n",
              "      <td>non_causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1524</th>\n",
              "      <td>drum</td>\n",
              "      <td>ear</td>\n",
              "      <td>non_causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1226</th>\n",
              "      <td>work</td>\n",
              "      <td>difficulties</td>\n",
              "      <td>non_causal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        cause        effect       label\n",
              "1465  protein   researchers  non_causal\n",
              "921     rocks          pile  non_causal\n",
              "1349   copper        tissue  non_causal\n",
              "949   article    criticisms  non_causal\n",
              "1524     drum           ear  non_causal\n",
              "1226     work  difficulties  non_causal"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzj5z2WC4pY5",
        "colab_type": "code",
        "outputId": "78e2383c-fa50-4977-a014-d9f2cd449e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "risk_df = pd.read_csv(risk_file_path, names=['cause', 'effect', 'label'], header=None)\n",
        "risk_df['cause'] = risk_df['cause'].apply(lambda x: re.sub('\\s\\[\\d+\\]$', '', x))  # remove '[n]' from the end\n",
        "risk_df['effect'] = risk_df['effect'].apply(lambda x: re.sub('\\s\\[\\d+\\]$', '', x))  # remove '[n]' from the end\n",
        "risk_df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cause</th>\n",
              "      <th>effect</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>new competitors</td>\n",
              "      <td>increasing profits for our clients</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>new competitors</td>\n",
              "      <td>increased speed efficiency, and lower cost</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>increased speed efficiency, and lower cost</td>\n",
              "      <td>increasing profits for our clients</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>increased speed efficiency, and lower cost</td>\n",
              "      <td>increasing profits for our clients</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>changing market driving the needs for new busi...</td>\n",
              "      <td>increased importance of bundling products</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               cause  ...   label\n",
              "0                                    new competitors  ...  causal\n",
              "1                                    new competitors  ...  causal\n",
              "2         increased speed efficiency, and lower cost  ...  causal\n",
              "3         increased speed efficiency, and lower cost  ...  causal\n",
              "4  changing market driving the needs for new busi...  ...  causal\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgiJs3tx4qAh",
        "colab_type": "code",
        "outputId": "566828ff-24f1-4069-f7bb-f8a0ee3d298b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "nato_sfa_df = pd.read_csv(nato_sfa_file_path, names=['cause', 'effect', 'label'], header=None)\n",
        "nato_sfa_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cause</th>\n",
              "      <th>effect</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Increased global inequality</td>\n",
              "      <td>Migration</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Natural disasters</td>\n",
              "      <td>Unavailability of national military assets due...</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Increasingly connected human networks</td>\n",
              "      <td>An increasing need to understand human networks</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fractured and/or polarized societies</td>\n",
              "      <td>Instability and civil war</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fractured and/or polarized societies</td>\n",
              "      <td>Instability along NATO’s border causing large-...</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   cause  ...   label\n",
              "0            Increased global inequality  ...  causal\n",
              "1                      Natural disasters  ...  causal\n",
              "2  Increasingly connected human networks  ...  causal\n",
              "3   Fractured and/or polarized societies  ...  causal\n",
              "4   Fractured and/or polarized societies  ...  causal\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkoifUX04uJv",
        "colab_type": "code",
        "outputId": "ebccafe1-0eef-4878-ecd8-d85eb45954bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ce_me_df = pd.read_csv(ce_me_file_path, names=['cause', 'effect', 'label'], header=None)\n",
        "ce_me_df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cause</th>\n",
              "      <th>effect</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A strong dollar and a low oil price</td>\n",
              "      <td>profits of multinationals have dropped by 25%</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>country increases imports</td>\n",
              "      <td>country decreasing balance of trade</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>plunge in the value of local currency</td>\n",
              "      <td>country decreasing foreign reserves</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>increase in national debt</td>\n",
              "      <td>decrease in real annual economic growth</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>increase in the demand for a currency</td>\n",
              "      <td>rise in the exchange rate</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   cause  ...   label\n",
              "0    A strong dollar and a low oil price  ...  causal\n",
              "1              country increases imports  ...  causal\n",
              "2  plunge in the value of local currency  ...  causal\n",
              "3              increase in national debt  ...  causal\n",
              "4  increase in the demand for a currency  ...  causal\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnDC2l00-9io",
        "colab_type": "code",
        "outputId": "b04257a3-147f-4f7e-98fe-21aa5407db45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ce_twitter_df = pd.read_csv(ce_twitter_file_path)\n",
        "ce_twitter_df['label'] = ce_twitter_df['label'].apply(lambda x: 'non_causal' if x == 'not-causal' else x)\n",
        "ce_twitter_df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cause</th>\n",
              "      <th>effect</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i ned to be front and centre</td>\n",
              "      <td>it’s al about me</td>\n",
              "      <td>non_causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>families truly suport girl-child</td>\n",
              "      <td>we can se that sky to is not the limit</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>blinding youth with pelet guns was a #comonwea...</td>\n",
              "      <td>india would win a gold every hour</td>\n",
              "      <td>non_causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>they were so intolerant to an individuals thou...</td>\n",
              "      <td>they cant telecast #comonwealthgames2018 medal...</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>you can't wait until then</td>\n",
              "      <td>you can watch it here:</td>\n",
              "      <td>causal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               cause  ...       label\n",
              "0                       i ned to be front and centre  ...  non_causal\n",
              "1                   families truly suport girl-child  ...      causal\n",
              "2  blinding youth with pelet guns was a #comonwea...  ...  non_causal\n",
              "3  they were so intolerant to an individuals thou...  ...      causal\n",
              "4                          you can't wait until then  ...      causal\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML9Mvddf5qtf",
        "colab_type": "text"
      },
      "source": [
        "### Perform Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25lc2hWw49aO",
        "colab_type": "code",
        "outputId": "24a9a3ba-dbe3-419a-d450-1a7f7e8f423d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "causal_strength_calculator = CausalStrengthCalculator(CAUSAL_NET_FILE)\n",
        "\n",
        "# causal_strength_calculator.get_causality_score(('blindness', 'disease'))\n",
        "\n",
        "def get_causality_decisions_extended(candidate_pairs):\n",
        "  preds = []\n",
        "\n",
        "  for candidate_pair in candidate_pairs:\n",
        "    x_may_cause_y_score = causal_strength_calculator.get_causality_score((candidate_pair[0], candidate_pair[1]))\n",
        "    y_may_cause_x_score = causal_strength_calculator.get_causality_score((candidate_pair[1], candidate_pair[0]))\n",
        "\n",
        "    pred = (0.0, 0.0)\n",
        "    \n",
        "    sum = x_may_cause_y_score + y_may_cause_x_score\n",
        "    if sum > 0:\n",
        "      pred = (y_may_cause_x_score/sum, x_may_cause_y_score/sum)\n",
        "    preds.append(pred)\n",
        "  # print(preds)\n",
        "  pred_labels = np.argmax(preds, axis=1).flatten()\n",
        "\n",
        "  # pred_labels = []\n",
        "  # for pred in preds:\n",
        "  #   pred_label = 1\n",
        "  #   if pred[0] > 0.0 or pred[1] > 0.0:\n",
        "  #     if pred[0] < pred[1]:\n",
        "  #       pred_label = 0\n",
        "  #   pred_labels.append(pred_label)\n",
        "\n",
        "  return pred_labels\n",
        "\n",
        "def get_causality_decisions(candidate_pairs):\n",
        "  pred_labels = []\n",
        "\n",
        "  for candidate_pair in candidate_pairs:\n",
        "    x_may_cause_y_score = causal_strength_calculator.get_causality_score((candidate_pair[0], candidate_pair[1]))\n",
        "    pred_label = 0\n",
        "    if x_may_cause_y_score > 0:\n",
        "      pred_label = 1\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "  return pred_labels\n",
        "\n",
        "def evaluate(candidate_pairs, gold_labels):\n",
        "\n",
        "  predictions = get_causality_decisions(candidate_pairs)\n",
        "  # predictions = get_causality_decisions_extended(candidate_pairs)\n",
        "\n",
        "  tn, fp, fn, tp = confusion_matrix(gold_labels, predictions).ravel() \n",
        "  scores = {\n",
        "    # 'matthews_corrcoef_acc': matthews_corrcoef(gold_labels, predictions),\n",
        "    'true_positive': tp,\n",
        "    'false_positive': fp,\n",
        "    'precision': precision_score(gold_labels, predictions),\n",
        "    'recall': recall_score(gold_labels, predictions),\n",
        "    'f1_score': f1_score(gold_labels, predictions),\n",
        "    'accuracy': accuracy_score(gold_labels, predictions),\n",
        "    'auc': roc_auc_score(gold_labels, predictions)\n",
        "  }\n",
        "\n",
        "  return scores\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) \n",
        "\n",
        "dataset_dfs = [sem_eval_df, nato_sfa_df, risk_df, ce_me_df, ce_twitter_df]\n",
        "dataset_names = ['SemEval', 'NATO-SFA', 'Risk Models', 'CE Pairs', 'Twitter']\n",
        "\n",
        "# print('Dataset, accuracy, Precision, Recall, F1-score')\n",
        "\n",
        "for dataset_df, dataset_name in zip(dataset_dfs, dataset_names):\n",
        "  assert(len(dataset_df['cause']) == len(dataset_df['effect']))\n",
        "  candidate_pairs = zip(dataset_df['cause'].tolist(), dataset_df['effect'].tolist())\n",
        "  labels = [1 if label=='causal' else 0 for label in dataset_df['label'].tolist()]\n",
        "\n",
        "  scores = evaluate(candidate_pairs, labels)\n",
        "  print('{}, {}, {}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}'.format(dataset_name, scores['true_positive'], scores['false_positive'], scores['accuracy'], scores['precision'], scores['recall'], scores['f1_score'], scores['auc']))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SemEval, 79, 50, 0.5168, 0.6124, 0.0913, 0.1590, 0.5168\n",
            "NATO-SFA, 20, 16, 0.5339, 0.5556, 0.3390, 0.4211, 0.5339\n",
            "Risk Models, 320, 328, 0.4900, 0.4938, 0.7960, 0.6095, 0.4900\n",
            "CE Pairs, 99, 93, 0.5188, 0.5156, 0.6188, 0.5625, 0.5187\n",
            "Twitter, 232, 192, 0.5426, 0.5472, 0.5054, 0.5255, 0.5427\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}